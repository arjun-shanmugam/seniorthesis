{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3ec9a55-bce5-421c-97d3-6ca0e3e085d3",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3b61854-5418-4688-84a4-e3f2933d946a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T19:55:22.346500Z",
     "start_time": "2023-11-26T19:55:20.724428Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashanmu1/Documents/GitHub/seniorthesis/venv/lib/python3.10/site-packages/geopandas/_compat.py:123: UserWarning: The Shapely GEOS version (3.11.1-CAPI-1.17.1) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n",
      "/var/folders/d2/xc40wfzn765fbyjgk7fz021r0000gn/T/ipykernel_63015/3887947359.py:6: UserWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas will still use PyGEOS by default for now. To force to use and test Shapely 2.0, you have to set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:\n",
      "\n",
      "import os\n",
      "os.environ['USE_PYGEOS'] = '0'\n",
      "import geopandas\n",
      "\n",
      "In a future release, GeoPandas will switch to using Shapely by default. If you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).\n",
      "  import geopandas as gpd\n"
     ]
    }
   ],
   "source": [
    "import contextily as cx\n",
    "import figure_utilities\n",
    "import statsmodels.api as sm\n",
    "import constants\n",
    "from stats_utilities import produce_summary_statistics, select_controls, test_balance\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from panel_utilities import get_value_variable_names, prepare_df_for_DiD\n",
    "import numpy as np\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2fa6183-058d-4fef-8606-efcabc7e5dd1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T19:55:22.348865Z",
     "start_time": "2023-11-26T19:55:22.347201Z"
    }
   },
   "outputs": [],
   "source": [
    "# Store paths.\n",
    "INPUT_DATA_PANEL = \"../data/03_cleaned/crime_analysis_monthly.csv\"\n",
    "INPUT_DATA_TRACTS = \"../data/02_intermediate/tracts.csv\"\n",
    "INPUT_DATA_BOSTON_TRACTS_SHAPEFILE = \"../data/01_raw/Census_2010_Tracts\"\n",
    "INPUT_DATA_OFFENSE_CODES = \"../data/01_raw/rmsoffensecodes.xlsx\"\n",
    "OUTPUT_TABLES = \"../output/final_paper/tables\"\n",
    "OUTPUT_FIGURES = \"../output/final_paper/figures\"\n",
    "OUTPUT_STATISTICS = \"../output/final_paper/statistics.tex\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1003ebb9",
   "metadata": {},
   "source": [
    "# Summary Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0c226d-339f-4462-9a1b-e9a7e55f054f",
   "metadata": {},
   "source": [
    "## Map of Evictions, Colored by Poverty Rate in Census Tract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d4fdba9-e227-4f10-b853-a77712030e3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T15:22:50.331120Z",
     "start_time": "2023-11-26T15:22:48.742549Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read unrestricted dataset into memory.\n",
    "df = pd.read_csv(INPUT_DATA_PANEL)\n",
    "df = df.reset_index() # So we can use 'case_number' like a column\n",
    "\n",
    "# Create spatial data \n",
    "unrestricted_gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df['Longitude'], df['Latitude']))\n",
    "unrestricted_gdf = unrestricted_gdf.set_crs(\"EPSG:4326\")\n",
    "unrestricted_gdf = unrestricted_gdf.to_crs(\"EPSG:3857\")\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(8, 10))\n",
    "ax.set_yticklabels([])\n",
    "ax.set_yticks([])\n",
    "ax.set_xticklabels([])\n",
    "ax.set_xticks([])\n",
    "unrestricted_gdf.plot(ax=ax,\n",
    "                      color='black',\n",
    "                      markersize=0.05)\n",
    "cx.add_basemap(ax=ax, crs=\"EPSG:3857\", source=cx.providers.CartoDB.Positron)\n",
    "\n",
    "# Color census tracts by poverty rate.\n",
    "boston_tracts_gdf = gpd.read_file(INPUT_DATA_BOSTON_TRACTS_SHAPEFILE)[['GEOID10', 'geometry']].set_index('GEOID10')\n",
    "boston_tracts_gdf.index = boston_tracts_gdf.index.astype(int)\n",
    "tract_poverty_rates_df = pd.read_csv(INPUT_DATA_TRACTS, usecols=['tract_geoid', 'poor_share2010'],\n",
    "                                     index_col='tract_geoid')\n",
    "boston_tracts_gdf = pd.concat([boston_tracts_gdf, tract_poverty_rates_df], axis=1).dropna(\n",
    "    subset=['geometry', 'poor_share2010']).drop(index=25025990101)\n",
    "boston_tracts_gdf.plot(ax=ax, column=boston_tracts_gdf['poor_share2010'], cmap='OrRd', alpha=0.4, legend=True,\n",
    "                       legend_kwds={'label': \"Poverty Rate of Census Tract\",\n",
    "                                    'orientation': \"horizontal\",\n",
    "                                    'shrink': 0.25})\n",
    "\n",
    "figure_utilities.save_figure_and_close(fig, os.path.join(OUTPUT_FIGURES, \"evictions_map.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcbcccd",
   "metadata": {},
   "source": [
    "## Eviction Filings Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "449c0077-c2b3-4d73-a4b3-ec0362da8a73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T15:22:50.538983Z",
     "start_time": "2023-11-26T15:22:50.335367Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the number of eviction filings over time.\n",
    "df.loc[:, 'last_day_of_file_month'] = (pd.to_datetime(df['file_date']) +\n",
    "                                       pd.tseries.offsets.MonthEnd(0))\n",
    "filings_per_month = df.groupby('last_day_of_file_month')['case_number'].count()\n",
    "\n",
    "# Plot eviction filing counts.\n",
    "fig, ax = plt.subplots()\n",
    "filings_per_month.plot(ax=ax, kind='line', color='black',\n",
    "                       zorder=100)\n",
    "ax.set_ylabel(\"Number of Evictions\")\n",
    "ax.set_xlabel(\"Month\")\n",
    "ax.grid(True)\n",
    "figure_utilities.save_figure_and_close(fig, os.path.join(OUTPUT_FIGURES, \"filings_over_time.png\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5e109df-ed26-4b8a-af96-7ff95a7e0c6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T17:25:35.312113Z",
     "start_time": "2023-11-26T17:25:34.903415Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['total_twenty_eighteen_group_8_crimes_250m', 'pre_treatment_change_in_group_8_crimes_250m', 'relative_pre_treatment_change_in_group_8_crimes_250m', 'total_twenty_eighteen_group_8_crimes_300m', 'pre_treatment_change_in_group_8_crimes_300m', 'relative_pre_treatment_change_in_group_8_crimes_300m', 'total_twenty_eighteen_group_8_crimes_350m', 'pre_treatment_change_in_group_8_crimes_350m', 'relative_pre_treatment_change_in_group_8_crimes_350m', 'total_twenty_eighteen_group_8_crimes_250_to_300m', 'pre_treatment_change_in_group_8_crimes_250_to_300m', 'relative_pre_treatment_change_in_group_8_crimes_250_to_300m', 'total_twenty_eighteen_group_8_crimes_250_to_350m', 'pre_treatment_change_in_group_8_crimes_250_to_350m', 'relative_pre_treatment_change_in_group_8_crimes_250_to_350m', 'total_twenty_eighteen_group_8_crimes_250_to_400m', 'pre_treatment_change_in_group_8_crimes_250_to_400m', 'relative_pre_treatment_change_in_group_8_crimes_250_to_400m'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m treatment_date_variable \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatest_docket_date\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      8\u001b[0m outcomes_of_interest \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgroup_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_crimes_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstants\u001b[38;5;241m.\u001b[39mAnalysis\u001b[38;5;241m.\u001b[39mMAIN_RESULTS_RADIUS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m6\u001b[39m)]\n\u001b[0;32m----> 9\u001b[0m summary_statistics_unrestricted, variable_display_names_dict \u001b[38;5;241m=\u001b[39m \u001b[43mproduce_summary_statistics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Rename columns.\u001b[39;00m\n\u001b[1;32m     12\u001b[0m summary_statistics_unrestricted\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m summary_statistics_unrestricted\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mset_names([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPanel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVariable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/Documents/GitHub/seniorthesis/src/stats_utilities.py:265\u001b[0m, in \u001b[0;36mproduce_summary_statistics\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m    263\u001b[0m     panel_A_columns\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpre_treatment_change_in_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutcome\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    264\u001b[0m     panel_A_columns\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelative_pre_treatment_change_in_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutcome\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 265\u001b[0m panel_A \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpanel_A_columns\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mdescribe()\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m    266\u001b[0m panel_A \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([panel_A], keys\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPanel A: Pre-treatment Outcomes\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    268\u001b[0m \u001b[38;5;66;03m# Panel B: Census Tract Characteristics\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/seniorthesis/venv/lib/python3.10/site-packages/pandas/core/frame.py:3511\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3509\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3510\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3511\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3513\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3514\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/GitHub/seniorthesis/venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:5782\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5779\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5780\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 5782\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5784\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   5785\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   5786\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/seniorthesis/venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:5845\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5842\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5844\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 5845\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['total_twenty_eighteen_group_8_crimes_250m', 'pre_treatment_change_in_group_8_crimes_250m', 'relative_pre_treatment_change_in_group_8_crimes_250m', 'total_twenty_eighteen_group_8_crimes_300m', 'pre_treatment_change_in_group_8_crimes_300m', 'relative_pre_treatment_change_in_group_8_crimes_300m', 'total_twenty_eighteen_group_8_crimes_350m', 'pre_treatment_change_in_group_8_crimes_350m', 'relative_pre_treatment_change_in_group_8_crimes_350m', 'total_twenty_eighteen_group_8_crimes_250_to_300m', 'pre_treatment_change_in_group_8_crimes_250_to_300m', 'relative_pre_treatment_change_in_group_8_crimes_250_to_300m', 'total_twenty_eighteen_group_8_crimes_250_to_350m', 'pre_treatment_change_in_group_8_crimes_250_to_350m', 'relative_pre_treatment_change_in_group_8_crimes_250_to_350m', 'total_twenty_eighteen_group_8_crimes_250_to_400m', 'pre_treatment_change_in_group_8_crimes_250_to_400m', 'relative_pre_treatment_change_in_group_8_crimes_250_to_400m'] not in index\""
     ]
    }
   ],
   "source": [
    "# Read unrestricted dataset into memory.\n",
    "df = pd.read_csv(INPUT_DATA_PANEL)\n",
    "df = df.reset_index() # So we can use 'case_number' like a column\n",
    "\n",
    "# Produce summary statistics table.\n",
    "treatment_date_variable = 'latest_docket_date'\n",
    "\n",
    "outcomes_of_interest = [f'group_{i}_crimes_{constants.Analysis.MAIN_RESULTS_RADIUS}m' for i in range(6)]\n",
    "summary_statistics_unrestricted, variable_display_names_dict = produce_summary_statistics(df)\n",
    "\n",
    "# Rename columns.\n",
    "summary_statistics_unrestricted.index = summary_statistics_unrestricted.index.set_names([\"Panel\", \"Variable\"])\n",
    "column_display_names_dict = {'mean': \"Mean\", 'std': \"S.D.\", 'count': \"N\", '50%': 'Median'}\n",
    "summary_statistics_unrestricted = summary_statistics_unrestricted.sort_values(['Panel', 'Variable'])\n",
    "\n",
    "# Keep only outcomes of interest\n",
    "for outcome in constants.Variables.outcomes:\n",
    "\n",
    "    if outcome not in outcomes_of_interest:\n",
    "        summary_statistics_unrestricted = summary_statistics_unrestricted.drop(f'total_twenty_eighteen_{outcome}',\n",
    "                                                                                   level=1, axis=0)\n",
    "        summary_statistics_unrestricted = summary_statistics_unrestricted.drop(f'relative_pre_treatment_change_in_{outcome}',\n",
    "                                                                                   level=1, axis=0)\n",
    "        summary_statistics_unrestricted = summary_statistics_unrestricted.drop(f'pre_treatment_change_in_{outcome}',\n",
    "                                                                                   level=1, axis=0)\n",
    "\n",
    "\n",
    "# Drop median column.\n",
    "summary_statistics_unrestricted = summary_statistics_unrestricted.drop(columns='50%')\n",
    "\n",
    "# Export to LaTeX.\n",
    "filename = os.path.join(OUTPUT_TABLES, \"summary_statistics.tex\")\n",
    "latex = (summary_statistics_unrestricted\n",
    "         .rename(index=variable_display_names_dict)\n",
    "         .rename(columns=column_display_names_dict)\n",
    "         .style\n",
    "         .format(formatter={\n",
    "    'Mean': \"{:,.2f}\",\n",
    "    'Median': \"{:,.2f}\",\n",
    "    'S.D.': \"{:,.2f}\",\n",
    "    'N': \"{:,.0f}\"})\n",
    "         .format_index(\"\\\\textit{{{}}}\", escape=\"latex\", axis=0, level=0)\n",
    "         .to_latex(None,\n",
    "                   column_format=\"llcccc\",\n",
    "                   hrules=True,\n",
    "                   clines=\"skip-last;data\")).replace(\"{*}\", \"{3cm}\")\n",
    "with open(filename, 'w') as file:\n",
    "    file.write(latex)\n",
    "summary_statistics_unrestricted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3d970a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T16:31:45.545353Z",
     "start_time": "2023-11-26T16:31:45.541940Z"
    }
   },
   "outputs": [],
   "source": [
    "# Share of non entity plaintiffs who are represented by an attorney\n",
    "share_non_entity_plaintiffs_with_attorney = (100 * df.loc[df['isEntityP'] == 0, 'hasAttyP'].mean()).round(2)\n",
    "\n",
    "with open(OUTPUT_STATISTICS, 'w') as file:\n",
    "    file.write(f\"\\n\\\\def\\\\share_non_entity_plaintiffs_with_attorney{'{' + str(share_non_entity_plaintiffs_with_attorney) + '}'}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfea1a77-c928-478d-b750-268bd1bcb3ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T15:22:50.983010Z",
     "start_time": "2023-11-26T15:22:50.949332Z"
    }
   },
   "outputs": [],
   "source": [
    "# Produce treatment timings table.\n",
    "treatment_timings = (df\n",
    "                     .groupby(['latest_docket_month', 'judgment_for_plaintiff'])['case_number']\n",
    "                     .count()\n",
    "                     .reset_index()\n",
    "                     .fillna(0))\n",
    "treatment_timings = treatment_timings.pivot(index='latest_docket_month', columns='judgment_for_plaintiff').fillna(0)\n",
    "treatment_timings.columns = [\"Cases Won By Defendant\", \"Cases Won By Plaintiff\"]\n",
    "portion_of_all_cases = (treatment_timings['Cases Won By Plaintiff'] + treatment_timings[\n",
    "    'Cases Won By Defendant']) / len(df)\n",
    "treatment_timings = pd.concat([treatment_timings, portion_of_all_cases.rename('Portion of All Cases')], axis=1)\n",
    "sum_across_filing_date = pd.DataFrame(treatment_timings.sum(axis=0)).T\n",
    "sum_across_filing_date.index = [\"All Months\"]\n",
    "treatment_timings = pd.concat([sum_across_filing_date, treatment_timings], axis=0)\n",
    "treatment_timings.index = treatment_timings.index.rename(\"Last Docket Date\")\n",
    "\n",
    "# Export to LaTeX.\n",
    "filename = os.path.join(OUTPUT_TABLES, \"treatment_timings.tex\")\n",
    "treatment_timings.style.format(formatter={'Cases Won By Plaintiff': '{:,.0f}',\n",
    "                                          'Cases Won By Defendant': '{:,.0f}',\n",
    "                                          'Portion of All Cases': '{:0.2f}'}).to_latex(filename, column_format=\"lccc\",\n",
    "                                                                                       hrules=True)\n",
    "treatment_timings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6c8b3f-eba4-42a8-8690-2b4a55f8c823",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T16:33:07.557316Z",
     "start_time": "2023-11-26T16:33:07.548466Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate percent of cases which are in high poverty neighborhoods.\n",
    "df = df.loc[df['judgment_for_plaintiff'] == 1, :]\n",
    "original_N = len(df)\n",
    "cases_in_poor_tracts = len(df.loc[df['poor_share2010'] > 0.20, :])\n",
    "share_cases_in_poor_tracts = round(100 * (cases_in_poor_tracts / original_N), 2)\n",
    "with open(OUTPUT_STATISTICS, 'a') as file:\n",
    "    file.write(f\"\\n\\\\def\\\\share_cases_in_poor_tracts{'{' + str(share_cases_in_poor_tracts) + '}'}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32ce6dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T20:02:46.911015Z",
     "start_time": "2023-11-26T20:02:46.878102Z"
    }
   },
   "outputs": [],
   "source": [
    "# Produce table describing crime groups and their frequency\n",
    "columns = ['Offense Code', 'Description']\n",
    "# Read offense codes and their descriptions from BPD spreadsheet\n",
    "offense_codes_and_descriptions = pd.read_excel(INPUT_DATA_OFFENSE_CODES)\n",
    "offense_codes_and_descriptions.columns = columns\n",
    "offense_codes_and_descriptions = offense_codes_and_descriptions.set_index('Offense Code')\n",
    "\n",
    "group_0_crimes = pd.DataFrame([['All', '']], columns=columns)\n",
    "group_0_crimes = pd.concat([group_0_crimes], axis=0, keys=['All Crimes']).reset_index(level=1, drop=True)\n",
    "group_0_crimes.index.name = \"Incident Group\"\n",
    "group_0_crimes = group_0_crimes.reset_index().set_index([\"Incident Group\", 'Offense Code'])\n",
    "\n",
    "crime_group_dfs = [group_0_crimes]\n",
    "offense_code_groups = [constants.Analysis.larceny,\n",
    "                       constants.Analysis.motor_vehicle,\n",
    "                       constants.Analysis.vandalism,\n",
    "                       constants.Analysis.assault\n",
    "                       constants.Analysis.auto_theft]\n",
    "labels = [\"Larceny\", \"Motor Vehicle Accident\", \"Vandalism\", \"Assault\", \"Investigation\",  \"Auto Theft\"]\n",
    "for offense_codes, label in zip(offense_code_groups, labels):\n",
    "    crime_group_df = offense_codes_and_descriptions.loc[offense_codes, :].reset_index().drop_duplicates()\n",
    "    crime_group_df = pd.concat([crime_group_df], axis=0, keys=[label]).reset_index(level=1, drop=True)\n",
    "    crime_group_df.index.name = \"Incident Group\"\n",
    "    crime_group_df = crime_group_df.reset_index().set_index([\"Incident Group\", 'Offense Code'])\n",
    "    crime_group_dfs.append(crime_group_df)\n",
    "crime_group_df = pd.concat(crime_group_dfs, axis=0)\n",
    "\n",
    "# Export to LaTeX.\n",
    "# Clean description column to avoid silent LaTeX errrors\n",
    "crime_group_df.loc[:, 'Description'] = crime_group_df['Description'].str.replace(\"&\", \"\\\\&\", regex=False)\n",
    "crime_group_df.loc[:, 'Description'] = crime_group_df['Description'].str.replace(\"$\", \"\\\\$\", regex=False)\n",
    "\n",
    "# Split into two pages\n",
    "crime_group_df_page_1 = crime_group_df.loc[[\"Larceny\", \"Motor Vehicle Accident\"], :]\n",
    "crime_group_df_page_2 = crime_group_df.loc[[\"Vandalism\", \"Assault\",  \"Auto Theft\"], :]\n",
    "\n",
    "for df, page_number in zip([crime_group_df_page_1, crime_group_df_page_2], [1, 2]):\n",
    "    drop_for_space_reasons = \"RECOVERED - MV RECOVERED IN BOSTON (STOLEN OUTSIDE BOSTON)\"\n",
    "    latex = (df\n",
    "             .loc[df['Description'] != drop_for_space_reasons, :]\n",
    "             .style\n",
    "             .format_index(\"\\\\textit{{{}}}\", escape=\"latex\", axis=0, level=0)\n",
    "             .to_latex(None,\n",
    "                       column_format=\"lll\",\n",
    "                       hrules=True,\n",
    "                       clines=\"skip-last;data\"))\n",
    "    with open(os.path.join(OUTPUT_TABLES, f\"crime_groups_page_{page_number}.tex\"), 'w') as file:\n",
    "        file.write(latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bd1b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_group_df_page_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18a04cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_group_df_page_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1d9438",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
