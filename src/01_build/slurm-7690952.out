## SLURM PROLOG ###############################################################
##    Job ID : 7690952
##  Job Name : dask-worker
##  Nodelist : node1145
##      CPUs : 1
##  Mem/Node : 8192 MB
## Directory : /gpfs/home/ashanmu1/seniorthesis/src/01_build
##   Job Started : Sat Jan 28 19:18:17 EST 2023
###############################################################################
2023-01-28 19:18:18,055 - distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.207.45:39227'
2023-01-28 19:18:18,058 - distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.207.45:39580'
2023-01-28 19:18:18,059 - distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.207.45:43426'
2023-01-28 19:18:18,063 - distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.207.45:40372'
2023-01-28 19:18:19,171 - distributed.worker - INFO -       Start worker at:  tcp://172.20.207.45:43719
2023-01-28 19:18:19,171 - distributed.worker - INFO -       Start worker at:  tcp://172.20.207.45:35675
2023-01-28 19:18:19,175 - distributed.worker - INFO -          Listening to:  tcp://172.20.207.45:43719
2023-01-28 19:18:19,175 - distributed.worker - INFO -          Listening to:  tcp://172.20.207.45:35675
2023-01-28 19:18:19,175 - distributed.worker - INFO -           Worker name:           SLURMCluster-6-2
2023-01-28 19:18:19,175 - distributed.worker - INFO -           Worker name:           SLURMCluster-6-3
2023-01-28 19:18:19,175 - distributed.worker - INFO -          dashboard at:        172.20.207.45:40051
2023-01-28 19:18:19,175 - distributed.worker - INFO - Waiting to connect to:   tcp://172.20.207.1:40397
2023-01-28 19:18:19,175 - distributed.worker - INFO -          dashboard at:        172.20.207.45:41158
2023-01-28 19:18:19,175 - distributed.worker - INFO - -------------------------------------------------
2023-01-28 19:18:19,175 - distributed.worker - INFO - Waiting to connect to:   tcp://172.20.207.1:40397
2023-01-28 19:18:19,175 - distributed.worker - INFO - -------------------------------------------------
2023-01-28 19:18:19,175 - distributed.worker - INFO -               Threads:                          1
2023-01-28 19:18:19,175 - distributed.worker - INFO -               Threads:                          1
2023-01-28 19:18:19,175 - distributed.worker - INFO -                Memory:                   1.86 GiB
2023-01-28 19:18:19,175 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-94_sjtcq
2023-01-28 19:18:19,175 - distributed.worker - INFO -                Memory:                   1.86 GiB
2023-01-28 19:18:19,175 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-l75w4y2q
2023-01-28 19:18:19,175 - distributed.worker - INFO - -------------------------------------------------
2023-01-28 19:18:19,175 - distributed.worker - INFO - -------------------------------------------------
2023-01-28 19:18:19,174 - distributed.worker - INFO -       Start worker at:  tcp://172.20.207.45:35197
2023-01-28 19:18:19,174 - distributed.worker - INFO -       Start worker at:  tcp://172.20.207.45:40049
2023-01-28 19:18:19,176 - distributed.worker - INFO -          Listening to:  tcp://172.20.207.45:35197
2023-01-28 19:18:19,176 - distributed.worker - INFO -          Listening to:  tcp://172.20.207.45:40049
2023-01-28 19:18:19,176 - distributed.worker - INFO -           Worker name:           SLURMCluster-6-0
2023-01-28 19:18:19,176 - distributed.worker - INFO -           Worker name:           SLURMCluster-6-1
2023-01-28 19:18:19,176 - distributed.worker - INFO -          dashboard at:        172.20.207.45:44934
2023-01-28 19:18:19,176 - distributed.worker - INFO -          dashboard at:        172.20.207.45:39557
2023-01-28 19:18:19,176 - distributed.worker - INFO - Waiting to connect to:   tcp://172.20.207.1:40397
2023-01-28 19:18:19,176 - distributed.worker - INFO - -------------------------------------------------
2023-01-28 19:18:19,176 - distributed.worker - INFO - Waiting to connect to:   tcp://172.20.207.1:40397
2023-01-28 19:18:19,176 - distributed.worker - INFO -               Threads:                          1
2023-01-28 19:18:19,178 - distributed.worker - INFO - -------------------------------------------------
2023-01-28 19:18:19,178 - distributed.worker - INFO -                Memory:                   1.86 GiB
2023-01-28 19:18:19,178 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-pz49bdr3
2023-01-28 19:18:19,178 - distributed.worker - INFO - -------------------------------------------------
2023-01-28 19:18:19,178 - distributed.worker - INFO -               Threads:                          1
2023-01-28 19:18:19,178 - distributed.worker - INFO -                Memory:                   1.86 GiB
2023-01-28 19:18:19,178 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-ckky962h
2023-01-28 19:18:19,178 - distributed.worker - INFO - -------------------------------------------------
2023-01-28 19:18:19,196 - distributed.worker - INFO -         Registered to:   tcp://172.20.207.1:40397
2023-01-28 19:18:19,197 - distributed.worker - INFO - -------------------------------------------------
2023-01-28 19:18:19,197 - distributed.core - INFO - Starting established connection to tcp://172.20.207.1:40397
2023-01-28 19:18:19,198 - distributed.worker - INFO -         Registered to:   tcp://172.20.207.1:40397
2023-01-28 19:18:19,198 - distributed.worker - INFO - -------------------------------------------------
2023-01-28 19:18:19,198 - distributed.core - INFO - Starting established connection to tcp://172.20.207.1:40397
2023-01-28 19:18:19,199 - distributed.worker - INFO -         Registered to:   tcp://172.20.207.1:40397
2023-01-28 19:18:19,199 - distributed.worker - INFO - -------------------------------------------------
2023-01-28 19:18:19,200 - distributed.core - INFO - Starting established connection to tcp://172.20.207.1:40397
2023-01-28 19:18:19,200 - distributed.worker - INFO -         Registered to:   tcp://172.20.207.1:40397
2023-01-28 19:18:19,200 - distributed.worker - INFO - -------------------------------------------------
2023-01-28 19:18:19,201 - distributed.core - INFO - Starting established connection to tcp://172.20.207.1:40397
/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/geopandas/_compat.py:123: UserWarning: The Shapely GEOS version (3.11.1-CAPI-1.17.1) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.
  warnings.warn(
/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/dask_geopandas/backends.py:13: UserWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas will still use PyGEOS by default for now. To force to use and test Shapely 2.0, you have to set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:

import os
os.environ['USE_PYGEOS'] = '0'
import geopandas

In a future release, GeoPandas will switch to using Shapely by default. If you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).
  import geopandas
/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/geopandas/_compat.py:123: UserWarning: The Shapely GEOS version (3.11.1-CAPI-1.17.1) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.
  warnings.warn(
/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/dask_geopandas/backends.py:13: UserWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas will still use PyGEOS by default for now. To force to use and test Shapely 2.0, you have to set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:

import os
os.environ['USE_PYGEOS'] = '0'
import geopandas

In a future release, GeoPandas will switch to using Shapely by default. If you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).
  import geopandas
Warning 1: organizePolygons() received an unexpected geometry.  Either a polygon with interior rings, or a polygon with less than 4 points, or a non-Polygon geometry.  Return arguments as a collection.
/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/geopandas/_compat.py:123: UserWarning: The Shapely GEOS version (3.11.1-CAPI-1.17.1) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.
  warnings.warn(
/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/dask_geopandas/backends.py:13: UserWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas will still use PyGEOS by default for now. To force to use and test Shapely 2.0, you have to set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:

import os
os.environ['USE_PYGEOS'] = '0'
import geopandas

In a future release, GeoPandas will switch to using Shapely by default. If you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).
  import geopandas
Warning 1: organizePolygons() received an unexpected geometry.  Either a polygon with interior rings, or a polygon with less than 4 points, or a non-Polygon geometry.  Return arguments as a collection.
/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/geopandas/_compat.py:123: UserWarning: The Shapely GEOS version (3.11.1-CAPI-1.17.1) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.
  warnings.warn(
/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/dask_geopandas/backends.py:13: UserWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas will still use PyGEOS by default for now. To force to use and test Shapely 2.0, you have to set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:

import os
os.environ['USE_PYGEOS'] = '0'
import geopandas

In a future release, GeoPandas will switch to using Shapely by default. If you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).
  import geopandas
Warning 1: organizePolygons() received an unexpected geometry.  Either a polygon with interior rings, or a polygon with less than 4 points, or a non-Polygon geometry.  Return arguments as a collection.
2023-01-28 19:40:30,936 - distributed.nanny.memory - WARNING - Worker tcp://172.20.207.45:40049 (pid=22336) exceeded 95% memory budget. Restarting...
2023-01-28 19:40:31,085 - distributed.nanny - INFO - Worker process 22336 was killed by signal 15
2023-01-28 19:40:31,099 - distributed.nanny - WARNING - Restarting worker
2023-01-28 19:40:31,870 - distributed.worker - INFO -       Start worker at:  tcp://172.20.207.45:42278
2023-01-28 19:40:31,871 - distributed.worker - INFO -          Listening to:  tcp://172.20.207.45:42278
2023-01-28 19:40:31,871 - distributed.worker - INFO -           Worker name:           SLURMCluster-6-1
2023-01-28 19:40:31,871 - distributed.worker - INFO -          dashboard at:        172.20.207.45:44801
2023-01-28 19:40:31,871 - distributed.worker - INFO - Waiting to connect to:   tcp://172.20.207.1:40397
2023-01-28 19:40:31,871 - distributed.worker - INFO - -------------------------------------------------
2023-01-28 19:40:31,871 - distributed.worker - INFO -               Threads:                          1
2023-01-28 19:40:31,871 - distributed.worker - INFO -                Memory:                   1.86 GiB
2023-01-28 19:40:31,871 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-vv_xflrw
2023-01-28 19:40:31,871 - distributed.worker - INFO - -------------------------------------------------
2023-01-28 19:40:31,876 - distributed.worker - INFO -         Registered to:   tcp://172.20.207.1:40397
2023-01-28 19:40:31,876 - distributed.worker - INFO - -------------------------------------------------
2023-01-28 19:40:31,876 - distributed.core - INFO - Starting established connection to tcp://172.20.207.1:40397
Warning 1: organizePolygons() received an unexpected geometry.  Either a polygon with interior rings, or a polygon with less than 4 points, or a non-Polygon geometry.  Return arguments as a collection.
slurmstepd: error: *** JOB 7690952 ON node1145 CANCELLED AT 2023-01-28T19:48:21 DUE TO TIME LIMIT ***
