## SLURM PROLOG ###############################################################
##    Job ID : 8172716
##  Job Name : dask-worker
##  Nodelist : node1359
##      CPUs : 1
##  Mem/Node : 220160 MB
## Directory : /gpfs/home/ashanmu1/seniorthesis/src/01_build
##   Job Started : Tue Feb  7 23:57:00 EST 2023
###############################################################################
2023-02-07 23:57:00,736 - distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.209.59:37601'
2023-02-07 23:57:00,736 - distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.209.59:37306'
2023-02-07 23:57:00,741 - distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.209.59:43727'
2023-02-07 23:57:00,743 - distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.209.59:42646'
2023-02-07 23:57:00,747 - distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.209.59:41709'
2023-02-07 23:57:00,750 - distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.209.59:42332'
2023-02-07 23:57:00,753 - distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.209.59:37382'
2023-02-07 23:57:00,753 - distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.209.59:44122'
2023-02-07 23:57:01,490 - distributed.worker - INFO -       Start worker at:  tcp://172.20.209.59:35031
2023-02-07 23:57:01,490 - distributed.worker - INFO -          Listening to:  tcp://172.20.209.59:35031
2023-02-07 23:57:01,490 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-6
2023-02-07 23:57:01,490 - distributed.worker - INFO -          dashboard at:        172.20.209.59:37701
2023-02-07 23:57:01,490 - distributed.worker - INFO - Waiting to connect to:   tcp://172.20.207.2:35512
2023-02-07 23:57:01,490 - distributed.worker - INFO - -------------------------------------------------
2023-02-07 23:57:01,490 - distributed.worker - INFO -               Threads:                          4
2023-02-07 23:57:01,490 - distributed.worker - INFO -                Memory:                  26.78 GiB
2023-02-07 23:57:01,490 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-jsrs208r
2023-02-07 23:57:01,491 - distributed.worker - INFO - -------------------------------------------------
2023-02-07 23:57:01,497 - distributed.worker - INFO -       Start worker at:  tcp://172.20.209.59:42009
2023-02-07 23:57:01,498 - distributed.worker - INFO -          Listening to:  tcp://172.20.209.59:42009
2023-02-07 23:57:01,498 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-5
2023-02-07 23:57:01,498 - distributed.worker - INFO -          dashboard at:        172.20.209.59:42052
2023-02-07 23:57:01,498 - distributed.worker - INFO - Waiting to connect to:   tcp://172.20.207.2:35512
2023-02-07 23:57:01,498 - distributed.worker - INFO - -------------------------------------------------
2023-02-07 23:57:01,498 - distributed.worker - INFO -               Threads:                          4
2023-02-07 23:57:01,498 - distributed.worker - INFO -                Memory:                  26.78 GiB
2023-02-07 23:57:01,498 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-wc8ygl5g
2023-02-07 23:57:01,498 - distributed.worker - INFO - -------------------------------------------------
2023-02-07 23:57:01,498 - distributed.worker - INFO -       Start worker at:  tcp://172.20.209.59:36404
2023-02-07 23:57:01,498 - distributed.worker - INFO -          Listening to:  tcp://172.20.209.59:36404
2023-02-07 23:57:01,498 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-3
2023-02-07 23:57:01,498 - distributed.worker - INFO -          dashboard at:        172.20.209.59:40427
2023-02-07 23:57:01,498 - distributed.worker - INFO - Waiting to connect to:   tcp://172.20.207.2:35512
2023-02-07 23:57:01,498 - distributed.worker - INFO - -------------------------------------------------
2023-02-07 23:57:01,498 - distributed.worker - INFO -               Threads:                          4
2023-02-07 23:57:01,499 - distributed.worker - INFO -         Registered to:   tcp://172.20.207.2:35512
2023-02-07 23:57:01,499 - distributed.worker - INFO -                Memory:                  26.78 GiB
2023-02-07 23:57:01,499 - distributed.worker - INFO - -------------------------------------------------
2023-02-07 23:57:01,499 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-pxvww7tw
2023-02-07 23:57:01,499 - distributed.worker - INFO - -------------------------------------------------
2023-02-07 23:57:01,500 - distributed.core - INFO - Starting established connection to tcp://172.20.207.2:35512
2023-02-07 23:57:01,510 - distributed.worker - INFO -         Registered to:   tcp://172.20.207.2:35512
2023-02-07 23:57:01,510 - distributed.worker - INFO - -------------------------------------------------
2023-02-07 23:57:01,510 - distributed.core - INFO - Starting established connection to tcp://172.20.207.2:35512
2023-02-07 23:57:01,511 - distributed.worker - INFO -         Registered to:   tcp://172.20.207.2:35512
2023-02-07 23:57:01,511 - distributed.worker - INFO - -------------------------------------------------
2023-02-07 23:57:01,511 - distributed.core - INFO - Starting established connection to tcp://172.20.207.2:35512
2023-02-07 23:57:01,511 - distributed.worker - INFO -       Start worker at:  tcp://172.20.209.59:42402
2023-02-07 23:57:01,511 - distributed.worker - INFO -          Listening to:  tcp://172.20.209.59:42402
2023-02-07 23:57:01,511 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-4
2023-02-07 23:57:01,511 - distributed.worker - INFO -          dashboard at:        172.20.209.59:44169
2023-02-07 23:57:01,511 - distributed.worker - INFO - Waiting to connect to:   tcp://172.20.207.2:35512
2023-02-07 23:57:01,511 - distributed.worker - INFO - -------------------------------------------------
2023-02-07 23:57:01,511 - distributed.worker - INFO -               Threads:                          4
2023-02-07 23:57:01,512 - distributed.worker - INFO -                Memory:                  26.78 GiB
2023-02-07 23:57:01,512 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-kakwfbc9
2023-02-07 23:57:01,512 - distributed.worker - INFO - -------------------------------------------------
2023-02-07 23:57:01,514 - distributed.worker - INFO -       Start worker at:  tcp://172.20.209.59:45669
2023-02-07 23:57:01,514 - distributed.worker - INFO -          Listening to:  tcp://172.20.209.59:45669
2023-02-07 23:57:01,514 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-1
2023-02-07 23:57:01,514 - distributed.worker - INFO -          dashboard at:        172.20.209.59:36272
2023-02-07 23:57:01,514 - distributed.worker - INFO - Waiting to connect to:   tcp://172.20.207.2:35512
2023-02-07 23:57:01,514 - distributed.worker - INFO - -------------------------------------------------
2023-02-07 23:57:01,514 - distributed.worker - INFO -               Threads:                          4
2023-02-07 23:57:01,514 - distributed.worker - INFO -                Memory:                  26.78 GiB
2023-02-07 23:57:01,514 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-4_zz1cjo
2023-02-07 23:57:01,514 - distributed.worker - INFO - -------------------------------------------------
2023-02-07 23:57:01,516 - distributed.worker - INFO -         Registered to:   tcp://172.20.207.2:35512
2023-02-07 23:57:01,517 - distributed.worker - INFO - -------------------------------------------------
2023-02-07 23:57:01,517 - distributed.core - INFO - Starting established connection to tcp://172.20.207.2:35512
2023-02-07 23:57:01,517 - distributed.worker - INFO -       Start worker at:  tcp://172.20.209.59:38970
2023-02-07 23:57:01,517 - distributed.worker - INFO -          Listening to:  tcp://172.20.209.59:38970
2023-02-07 23:57:01,517 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-0
2023-02-07 23:57:01,517 - distributed.worker - INFO -          dashboard at:        172.20.209.59:36970
2023-02-07 23:57:01,517 - distributed.worker - INFO - Waiting to connect to:   tcp://172.20.207.2:35512
2023-02-07 23:57:01,517 - distributed.worker - INFO - -------------------------------------------------
2023-02-07 23:57:01,517 - distributed.worker - INFO -               Threads:                          4
2023-02-07 23:57:01,517 - distributed.worker - INFO -                Memory:                  26.78 GiB
2023-02-07 23:57:01,517 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-x8mcv8g4
2023-02-07 23:57:01,517 - distributed.worker - INFO - -------------------------------------------------
2023-02-07 23:57:01,519 - distributed.worker - INFO -         Registered to:   tcp://172.20.207.2:35512
2023-02-07 23:57:01,519 - distributed.worker - INFO - -------------------------------------------------
2023-02-07 23:57:01,520 - distributed.core - INFO - Starting established connection to tcp://172.20.207.2:35512
2023-02-07 23:57:01,522 - distributed.worker - INFO -         Registered to:   tcp://172.20.207.2:35512
2023-02-07 23:57:01,522 - distributed.worker - INFO - -------------------------------------------------
2023-02-07 23:57:01,523 - distributed.core - INFO - Starting established connection to tcp://172.20.207.2:35512
2023-02-07 23:57:01,525 - distributed.worker - INFO -       Start worker at:  tcp://172.20.209.59:34378
2023-02-07 23:57:01,525 - distributed.worker - INFO -          Listening to:  tcp://172.20.209.59:34378
2023-02-07 23:57:01,525 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-2
2023-02-07 23:57:01,525 - distributed.worker - INFO -          dashboard at:        172.20.209.59:39513
2023-02-07 23:57:01,525 - distributed.worker - INFO - Waiting to connect to:   tcp://172.20.207.2:35512
2023-02-07 23:57:01,525 - distributed.worker - INFO - -------------------------------------------------
2023-02-07 23:57:01,525 - distributed.worker - INFO -               Threads:                          4
2023-02-07 23:57:01,526 - distributed.worker - INFO -                Memory:                  26.78 GiB
2023-02-07 23:57:01,526 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-acbjryfk
2023-02-07 23:57:01,526 - distributed.worker - INFO - -------------------------------------------------
2023-02-07 23:57:01,528 - distributed.worker - INFO -       Start worker at:  tcp://172.20.209.59:44448
2023-02-07 23:57:01,528 - distributed.worker - INFO -          Listening to:  tcp://172.20.209.59:44448
2023-02-07 23:57:01,528 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-7
2023-02-07 23:57:01,528 - distributed.worker - INFO -          dashboard at:        172.20.209.59:37109
2023-02-07 23:57:01,528 - distributed.worker - INFO - Waiting to connect to:   tcp://172.20.207.2:35512
2023-02-07 23:57:01,528 - distributed.worker - INFO - -------------------------------------------------
2023-02-07 23:57:01,528 - distributed.worker - INFO -               Threads:                          4
2023-02-07 23:57:01,528 - distributed.worker - INFO -                Memory:                  26.78 GiB
2023-02-07 23:57:01,528 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-o4h1sfc1
2023-02-07 23:57:01,528 - distributed.worker - INFO - -------------------------------------------------
2023-02-07 23:57:01,532 - distributed.worker - INFO -         Registered to:   tcp://172.20.207.2:35512
2023-02-07 23:57:01,532 - distributed.worker - INFO - -------------------------------------------------
2023-02-07 23:57:01,532 - distributed.core - INFO - Starting established connection to tcp://172.20.207.2:35512
2023-02-07 23:57:01,534 - distributed.worker - INFO -         Registered to:   tcp://172.20.207.2:35512
2023-02-07 23:57:01,534 - distributed.worker - INFO - -------------------------------------------------
2023-02-07 23:57:01,534 - distributed.core - INFO - Starting established connection to tcp://172.20.207.2:35512
/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/geopandas/_compat.py:123: UserWarning: The Shapely GEOS version (3.11.1-CAPI-1.17.1) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.
  warnings.warn(
/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/distributed/protocol/pickle.py:71: UserWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas will still use PyGEOS by default for now. To force to use and test Shapely 2.0, you have to set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:

import os
os.environ['USE_PYGEOS'] = '0'
import geopandas

In a future release, GeoPandas will switch to using Shapely by default. If you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).
  return pickle.loads(x, buffers=buffers)
/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/geopandas/_compat.py:123: UserWarning: The Shapely GEOS version (3.11.1-CAPI-1.17.1) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.
  warnings.warn(
/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/dask_geopandas/backends.py:13: UserWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas will still use PyGEOS by default for now. To force to use and test Shapely 2.0, you have to set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:

import os
os.environ['USE_PYGEOS'] = '0'
import geopandas

In a future release, GeoPandas will switch to using Shapely by default. If you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).
  import geopandas
2023-02-07 23:57:10,974 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/geopandas/_compat.py:123: UserWarning: The Shapely GEOS version (3.11.1-CAPI-1.17.1) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.
  warnings.warn(
/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/dask_geopandas/backends.py:13: UserWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas will still use PyGEOS by default for now. To force to use and test Shapely 2.0, you have to set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:

import os
os.environ['USE_PYGEOS'] = '0'
import geopandas

In a future release, GeoPandas will switch to using Shapely by default. If you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).
  import geopandas
/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/geopandas/_compat.py:123: UserWarning: The Shapely GEOS version (3.11.1-CAPI-1.17.1) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.
  warnings.warn(
/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/distributed/protocol/pickle.py:71: UserWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas will still use PyGEOS by default for now. To force to use and test Shapely 2.0, you have to set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:

import os
os.environ['USE_PYGEOS'] = '0'
import geopandas

In a future release, GeoPandas will switch to using Shapely by default. If you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).
  return pickle.loads(x, buffers=buffers)
2023-02-07 23:57:21,016 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/geopandas/_compat.py:123: UserWarning: The Shapely GEOS version (3.11.1-CAPI-1.17.1) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.
  warnings.warn(
/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/distributed/protocol/pickle.py:71: UserWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas will still use PyGEOS by default for now. To force to use and test Shapely 2.0, you have to set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:

import os
os.environ['USE_PYGEOS'] = '0'
import geopandas

In a future release, GeoPandas will switch to using Shapely by default. If you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).
  return pickle.loads(x, buffers=buffers)
/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/geopandas/_compat.py:123: UserWarning: The Shapely GEOS version (3.11.1-CAPI-1.17.1) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.
  warnings.warn(
/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/distributed/protocol/pickle.py:71: UserWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas will still use PyGEOS by default for now. To force to use and test Shapely 2.0, you have to set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:

import os
os.environ['USE_PYGEOS'] = '0'
import geopandas

In a future release, GeoPandas will switch to using Shapely by default. If you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).
  return pickle.loads(x, buffers=buffers)
/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/dask/dataframe/io/csv.py:194: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.
  df = reader(bio, **kwargs)
/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/dask/dataframe/io/csv.py:194: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.
  df = reader(bio, **kwargs)
/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/dask/dataframe/io/csv.py:194: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.
  df = reader(bio, **kwargs)
/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/dask/dataframe/io/csv.py:194: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.
  df = reader(bio, **kwargs)
2023-02-08 00:06:19,297 - distributed.core - INFO - Connection to tcp://172.20.207.2:35512 has been closed.
2023-02-08 00:06:19,297 - distributed.core - INFO - Connection to tcp://172.20.207.2:35512 has been closed.
2023-02-08 00:06:19,297 - distributed.core - INFO - Connection to tcp://172.20.207.2:35512 has been closed.
2023-02-08 00:06:19,297 - distributed.core - INFO - Connection to tcp://172.20.207.2:35512 has been closed.
2023-02-08 00:06:19,297 - distributed.core - INFO - Connection to tcp://172.20.207.2:35512 has been closed.
2023-02-08 00:06:19,297 - distributed.core - INFO - Connection to tcp://172.20.207.2:35512 has been closed.
2023-02-08 00:06:19,297 - distributed.core - INFO - Connection to tcp://172.20.207.2:35512 has been closed.
2023-02-08 00:06:19,297 - distributed.core - INFO - Connection to tcp://172.20.207.2:35512 has been closed.
2023-02-08 00:06:19,314 - distributed.worker - INFO - Stopping worker at tcp://172.20.209.59:35031. Reason: worker-handle-scheduler-connection-broken
2023-02-08 00:06:19,314 - distributed.worker - INFO - Stopping worker at tcp://172.20.209.59:45669. Reason: worker-handle-scheduler-connection-broken
2023-02-08 00:06:19,314 - distributed.worker - INFO - Stopping worker at tcp://172.20.209.59:36404. Reason: worker-handle-scheduler-connection-broken
2023-02-08 00:06:19,314 - distributed.worker - INFO - Stopping worker at tcp://172.20.209.59:38970. Reason: worker-handle-scheduler-connection-broken
2023-02-08 00:06:19,314 - distributed.worker - INFO - Stopping worker at tcp://172.20.209.59:42009. Reason: worker-handle-scheduler-connection-broken
2023-02-08 00:06:19,314 - distributed.worker - INFO - Stopping worker at tcp://172.20.209.59:44448. Reason: worker-handle-scheduler-connection-broken
2023-02-08 00:06:19,314 - distributed.worker - INFO - Stopping worker at tcp://172.20.209.59:42402. Reason: worker-handle-scheduler-connection-broken
2023-02-08 00:06:19,314 - distributed.worker - INFO - Stopping worker at tcp://172.20.209.59:34378. Reason: worker-handle-scheduler-connection-broken
2023-02-08 00:06:19,314 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/tornado/iostream.py", line 869, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/tornado/iostream.py", line 1138, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/distributed/worker.py", line 1215, in heartbeat
    response = await retry_operation(
  File "/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/distributed/utils_comm.py", line 402, in retry_operation
    return await retry(
  File "/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/distributed/utils_comm.py", line 387, in retry
    return await coro()
  File "/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/distributed/core.py", line 1221, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/distributed/core.py", line 986, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/distributed/comm/tcp.py", line 241, in read
    convert_stream_closed_error(self, e)
  File "/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://172.20.209.59:35844 remote=tcp://172.20.207.2:35512>: ConnectionResetError: [Errno 104] Connection reset by peer
2023-02-08 00:06:19,315 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/tornado/iostream.py", line 869, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/tornado/iostream.py", line 1138, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/distributed/worker.py", line 1215, in heartbeat
    response = await retry_operation(
  File "/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/distributed/utils_comm.py", line 402, in retry_operation
    return await retry(
  File "/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/distributed/utils_comm.py", line 387, in retry
    return await coro()
  File "/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/distributed/core.py", line 1221, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/distributed/core.py", line 986, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/distributed/comm/tcp.py", line 241, in read
    convert_stream_closed_error(self, e)
  File "/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://172.20.209.59:35846 remote=tcp://172.20.207.2:35512>: ConnectionResetError: [Errno 104] Connection reset by peer
2023-02-08 00:06:19,320 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://172.20.209.59:43727'. Reason: worker-handle-scheduler-connection-broken
2023-02-08 00:06:19,320 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://172.20.209.59:37306'. Reason: worker-handle-scheduler-connection-broken
2023-02-08 00:06:19,321 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://172.20.209.59:37382'. Reason: worker-handle-scheduler-connection-broken
2023-02-08 00:06:19,321 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://172.20.209.59:42646'. Reason: worker-handle-scheduler-connection-broken
2023-02-08 00:06:19,321 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://172.20.209.59:42332'. Reason: worker-handle-scheduler-connection-broken
2023-02-08 00:06:19,322 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://172.20.209.59:37601'. Reason: worker-handle-scheduler-connection-broken
2023-02-08 00:06:19,322 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://172.20.209.59:41709'. Reason: worker-handle-scheduler-connection-broken
2023-02-08 00:06:19,322 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://172.20.209.59:44122'. Reason: worker-handle-scheduler-connection-broken
2023-02-08 00:06:19,323 - distributed.nanny - INFO - Worker closed
2023-02-08 00:06:19,323 - distributed.nanny - INFO - Worker closed
2023-02-08 00:06:19,324 - distributed.nanny - INFO - Worker closed
2023-02-08 00:06:19,324 - distributed.nanny - INFO - Worker closed
2023-02-08 00:06:19,324 - distributed.nanny - INFO - Worker closed
2023-02-08 00:06:19,324 - distributed.nanny - INFO - Worker closed
2023-02-08 00:06:19,325 - distributed.nanny - INFO - Worker closed
2023-02-08 00:06:19,325 - distributed.nanny - INFO - Worker closed
2023-02-08 00:06:21,324 - distributed.nanny - ERROR - Worker process died unexpectedly
2023-02-08 00:06:21,324 - distributed.nanny - ERROR - Worker process died unexpectedly
2023-02-08 00:06:21,326 - distributed.nanny - ERROR - Worker process died unexpectedly
2023-02-08 00:06:21,327 - distributed.nanny - ERROR - Worker process died unexpectedly
2023-02-08 00:06:21,575 - distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.209.59:41709'. Reason: nanny-close-gracefully
2023-02-08 00:06:21,578 - distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.209.59:44122'. Reason: nanny-close-gracefully
2023-02-08 00:06:21,642 - distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.209.59:42332'. Reason: nanny-close-gracefully
2023-02-08 00:06:21,652 - distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.209.59:37382'. Reason: nanny-close-gracefully
2023-02-08 00:06:21,678 - distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.209.59:37306'. Reason: nanny-close-gracefully
2023-02-08 00:06:21,731 - distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.209.59:42646'. Reason: nanny-close-gracefully
2023-02-08 00:06:21,763 - distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.209.59:43727'. Reason: nanny-close-gracefully
2023-02-08 00:06:21,781 - distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.209.59:37601'. Reason: nanny-close-gracefully
2023-02-08 00:06:21,782 - distributed.dask_worker - INFO - End worker
