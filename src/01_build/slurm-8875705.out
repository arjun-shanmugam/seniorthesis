## SLURM PROLOG ###############################################################
##    Job ID : 8875705
##  Job Name : dask-worker
##  Nodelist : node2202
##      CPUs : 1
##  Mem/Node : 220160 MB
## Directory : /gpfs/home/ashanmu1/seniorthesis/src/01_build
##   Job Started : Sat Feb 25 11:03:12 EST 2023
###############################################################################
2023-02-25 11:03:14,052 - distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.218.2:32821'
2023-02-25 11:03:14,059 - distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.218.2:42992'
2023-02-25 11:03:14,060 - distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.218.2:40441'
2023-02-25 11:03:14,061 - distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.218.2:33492'
2023-02-25 11:03:14,061 - distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.218.2:39567'
2023-02-25 11:03:14,067 - distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.218.2:36543'
2023-02-25 11:03:14,071 - distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.218.2:33160'
2023-02-25 11:03:14,071 - distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.218.2:33718'
2023-02-25 11:03:15,664 - distributed.worker - INFO -       Start worker at:   tcp://172.20.218.2:44028
2023-02-25 11:03:15,664 - distributed.worker - INFO -       Start worker at:   tcp://172.20.218.2:39547
2023-02-25 11:03:15,664 - distributed.worker - INFO -       Start worker at:   tcp://172.20.218.2:34562
2023-02-25 11:03:15,665 - distributed.worker - INFO -          Listening to:   tcp://172.20.218.2:44028
2023-02-25 11:03:15,665 - distributed.worker - INFO -       Start worker at:   tcp://172.20.218.2:46036
2023-02-25 11:03:15,664 - distributed.worker - INFO -       Start worker at:   tcp://172.20.218.2:38350
2023-02-25 11:03:15,664 - distributed.worker - INFO -       Start worker at:   tcp://172.20.218.2:41286
2023-02-25 11:03:15,665 - distributed.worker - INFO -          Listening to:   tcp://172.20.218.2:39547
2023-02-25 11:03:15,665 - distributed.worker - INFO -       Start worker at:   tcp://172.20.218.2:46794
2023-02-25 11:03:15,665 - distributed.worker - INFO -          Listening to:   tcp://172.20.218.2:34562
2023-02-25 11:03:15,665 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-6
2023-02-25 11:03:15,665 - distributed.worker - INFO -          Listening to:   tcp://172.20.218.2:46036
2023-02-25 11:03:15,665 - distributed.worker - INFO -          Listening to:   tcp://172.20.218.2:38350
2023-02-25 11:03:15,665 - distributed.worker - INFO -       Start worker at:   tcp://172.20.218.2:34723
2023-02-25 11:03:15,665 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-7
2023-02-25 11:03:15,665 - distributed.worker - INFO -          Listening to:   tcp://172.20.218.2:41286
2023-02-25 11:03:15,665 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-3
2023-02-25 11:03:15,665 - distributed.worker - INFO -          Listening to:   tcp://172.20.218.2:46794
2023-02-25 11:03:15,665 - distributed.worker - INFO -          dashboard at:         172.20.218.2:37983
2023-02-25 11:03:15,665 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-0
2023-02-25 11:03:15,665 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-4
2023-02-25 11:03:15,665 - distributed.worker - INFO -          dashboard at:         172.20.218.2:33316
2023-02-25 11:03:15,665 - distributed.worker - INFO -          Listening to:   tcp://172.20.218.2:34723
2023-02-25 11:03:15,665 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-2
2023-02-25 11:03:15,665 - distributed.worker - INFO -          dashboard at:         172.20.218.2:38726
2023-02-25 11:03:15,665 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-1
2023-02-25 11:03:15,665 - distributed.worker - INFO - Waiting to connect to:   tcp://172.20.207.1:38034
2023-02-25 11:03:15,665 - distributed.worker - INFO -          dashboard at:         172.20.218.2:44587
2023-02-25 11:03:15,666 - distributed.worker - INFO - -------------------------------------------------
2023-02-25 11:03:15,665 - distributed.worker - INFO -          dashboard at:         172.20.218.2:43553
2023-02-25 11:03:15,665 - distributed.worker - INFO -          dashboard at:         172.20.218.2:34105
2023-02-25 11:03:15,666 - distributed.worker - INFO - Waiting to connect to:   tcp://172.20.207.1:38034
2023-02-25 11:03:15,665 - distributed.worker - INFO - Waiting to connect to:   tcp://172.20.207.1:38034
2023-02-25 11:03:15,666 - distributed.worker - INFO - Waiting to connect to:   tcp://172.20.207.1:38034
2023-02-25 11:03:15,666 - distributed.worker - INFO - Waiting to connect to:   tcp://172.20.207.1:38034
2023-02-25 11:03:15,666 - distributed.worker - INFO - -------------------------------------------------
2023-02-25 11:03:15,666 - distributed.worker - INFO - -------------------------------------------------
2023-02-25 11:03:15,666 - distributed.worker - INFO - -------------------------------------------------
2023-02-25 11:03:15,666 - distributed.worker - INFO - -------------------------------------------------
2023-02-25 11:03:15,665 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-5
2023-02-25 11:03:15,666 - distributed.worker - INFO -               Threads:                          4
2023-02-25 11:03:15,665 - distributed.worker - INFO - Waiting to connect to:   tcp://172.20.207.1:38034
2023-02-25 11:03:15,665 - distributed.worker - INFO -          dashboard at:         172.20.218.2:34596
2023-02-25 11:03:15,666 - distributed.worker - INFO -          dashboard at:         172.20.218.2:35762
2023-02-25 11:03:15,666 - distributed.worker - INFO -                Memory:                  26.78 GiB
2023-02-25 11:03:15,666 - distributed.worker - INFO - -------------------------------------------------
2023-02-25 11:03:15,666 - distributed.worker - INFO - Waiting to connect to:   tcp://172.20.207.1:38034
2023-02-25 11:03:15,666 - distributed.worker - INFO -               Threads:                          4
2023-02-25 11:03:15,666 - distributed.worker - INFO -               Threads:                          4
2023-02-25 11:03:15,666 - distributed.worker - INFO -               Threads:                          4
2023-02-25 11:03:15,666 - distributed.worker - INFO - Waiting to connect to:   tcp://172.20.207.1:38034
2023-02-25 11:03:15,666 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-_tndnygm
2023-02-25 11:03:15,666 - distributed.worker - INFO - -------------------------------------------------
2023-02-25 11:03:15,666 - distributed.worker - INFO -               Threads:                          4
2023-02-25 11:03:15,666 - distributed.worker - INFO -                Memory:                  26.78 GiB
2023-02-25 11:03:15,666 - distributed.worker - INFO -                Memory:                  26.78 GiB
2023-02-25 11:03:15,666 - distributed.worker - INFO - -------------------------------------------------
2023-02-25 11:03:15,666 - distributed.worker - INFO -                Memory:                  26.78 GiB
2023-02-25 11:03:15,666 - distributed.worker - INFO -               Threads:                          4
2023-02-25 11:03:15,666 - distributed.worker - INFO -                Memory:                  26.78 GiB
2023-02-25 11:03:15,666 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-mt0eixeb
2023-02-25 11:03:15,666 - distributed.worker - INFO - -------------------------------------------------
2023-02-25 11:03:15,666 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-t2c2n_ya
2023-02-25 11:03:15,666 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-9gdq7n7l
2023-02-25 11:03:15,666 - distributed.worker - INFO -                Memory:                  26.78 GiB
2023-02-25 11:03:15,666 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-qr1_ghu6
2023-02-25 11:03:15,666 - distributed.worker - INFO -               Threads:                          4
2023-02-25 11:03:15,666 - distributed.worker - INFO - -------------------------------------------------
2023-02-25 11:03:15,666 - distributed.worker - INFO -               Threads:                          4
2023-02-25 11:03:15,666 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-t0vjazt3
2023-02-25 11:03:15,666 - distributed.worker - INFO - -------------------------------------------------
2023-02-25 11:03:15,666 - distributed.worker - INFO - -------------------------------------------------
2023-02-25 11:03:15,666 - distributed.worker - INFO -                Memory:                  26.78 GiB
2023-02-25 11:03:15,666 - distributed.worker - INFO - -------------------------------------------------
2023-02-25 11:03:15,666 - distributed.worker - INFO -                Memory:                  26.78 GiB
2023-02-25 11:03:15,666 - distributed.worker - INFO - -------------------------------------------------
2023-02-25 11:03:15,666 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-8tols1pn
2023-02-25 11:03:15,666 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-78ecgwwb
2023-02-25 11:03:15,666 - distributed.worker - INFO - -------------------------------------------------
2023-02-25 11:03:15,666 - distributed.worker - INFO - -------------------------------------------------
2023-02-25 11:03:15,677 - distributed.worker - INFO -         Registered to:   tcp://172.20.207.1:38034
2023-02-25 11:03:15,678 - distributed.worker - INFO - -------------------------------------------------
2023-02-25 11:03:15,678 - distributed.core - INFO - Starting established connection to tcp://172.20.207.1:38034
2023-02-25 11:03:15,679 - distributed.worker - INFO -         Registered to:   tcp://172.20.207.1:38034
2023-02-25 11:03:15,679 - distributed.worker - INFO - -------------------------------------------------
2023-02-25 11:03:15,679 - distributed.core - INFO - Starting established connection to tcp://172.20.207.1:38034
2023-02-25 11:03:15,679 - distributed.worker - INFO -         Registered to:   tcp://172.20.207.1:38034
2023-02-25 11:03:15,679 - distributed.worker - INFO - -------------------------------------------------
2023-02-25 11:03:15,680 - distributed.core - INFO - Starting established connection to tcp://172.20.207.1:38034
2023-02-25 11:03:15,680 - distributed.worker - INFO -         Registered to:   tcp://172.20.207.1:38034
2023-02-25 11:03:15,680 - distributed.worker - INFO - -------------------------------------------------
2023-02-25 11:03:15,680 - distributed.core - INFO - Starting established connection to tcp://172.20.207.1:38034
2023-02-25 11:03:15,681 - distributed.worker - INFO -         Registered to:   tcp://172.20.207.1:38034
2023-02-25 11:03:15,681 - distributed.worker - INFO - -------------------------------------------------
2023-02-25 11:03:15,681 - distributed.core - INFO - Starting established connection to tcp://172.20.207.1:38034
2023-02-25 11:03:15,682 - distributed.worker - INFO -         Registered to:   tcp://172.20.207.1:38034
2023-02-25 11:03:15,682 - distributed.worker - INFO - -------------------------------------------------
2023-02-25 11:03:15,682 - distributed.core - INFO - Starting established connection to tcp://172.20.207.1:38034
2023-02-25 11:03:15,682 - distributed.worker - INFO -         Registered to:   tcp://172.20.207.1:38034
2023-02-25 11:03:15,683 - distributed.worker - INFO - -------------------------------------------------
2023-02-25 11:03:15,683 - distributed.core - INFO - Starting established connection to tcp://172.20.207.1:38034
2023-02-25 11:03:15,683 - distributed.worker - INFO -         Registered to:   tcp://172.20.207.1:38034
2023-02-25 11:03:15,683 - distributed.worker - INFO - -------------------------------------------------
2023-02-25 11:03:15,684 - distributed.core - INFO - Starting established connection to tcp://172.20.207.1:38034
/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/geopandas/_compat.py:123: UserWarning: The Shapely GEOS version (3.11.1-CAPI-1.17.1) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.
  warnings.warn(
/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/distributed/protocol/pickle.py:71: UserWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas will still use PyGEOS by default for now. To force to use and test Shapely 2.0, you have to set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:

import os
os.environ['USE_PYGEOS'] = '0'
import geopandas

In a future release, GeoPandas will switch to using Shapely by default. If you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).
  return pickle.loads(x, buffers=buffers)
/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/geopandas/_compat.py:123: UserWarning: The Shapely GEOS version (3.11.1-CAPI-1.17.1) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.
  warnings.warn(
/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/dask_geopandas/backends.py:13: UserWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas will still use PyGEOS by default for now. To force to use and test Shapely 2.0, you have to set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:

import os
os.environ['USE_PYGEOS'] = '0'
import geopandas

In a future release, GeoPandas will switch to using Shapely by default. If you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).
  import geopandas
2023-02-25 11:03:26,760 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/geopandas/_compat.py:123: UserWarning: The Shapely GEOS version (3.11.1-CAPI-1.17.1) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.
  warnings.warn(
/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/distributed/protocol/pickle.py:71: UserWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas will still use PyGEOS by default for now. To force to use and test Shapely 2.0, you have to set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:

import os
os.environ['USE_PYGEOS'] = '0'
import geopandas

In a future release, GeoPandas will switch to using Shapely by default. If you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).
  return pickle.loads(x, buffers=buffers)
2023-02-25 11:03:36,726 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/geopandas/_compat.py:123: UserWarning: The Shapely GEOS version (3.11.1-CAPI-1.17.1) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.
  warnings.warn(
/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/distributed/protocol/pickle.py:71: UserWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas will still use PyGEOS by default for now. To force to use and test Shapely 2.0, you have to set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:

import os
os.environ['USE_PYGEOS'] = '0'
import geopandas

In a future release, GeoPandas will switch to using Shapely by default. If you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).
  return pickle.loads(x, buffers=buffers)
/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/geopandas/_compat.py:123: UserWarning: The Shapely GEOS version (3.11.1-CAPI-1.17.1) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.
  warnings.warn(
/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/distributed/protocol/pickle.py:71: UserWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas will still use PyGEOS by default for now. To force to use and test Shapely 2.0, you have to set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:

import os
os.environ['USE_PYGEOS'] = '0'
import geopandas

In a future release, GeoPandas will switch to using Shapely by default. If you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).
  return pickle.loads(x, buffers=buffers)
2023-02-25 11:03:43,049 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/geopandas/_compat.py:123: UserWarning: The Shapely GEOS version (3.11.1-CAPI-1.17.1) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.
  warnings.warn(
/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/distributed/protocol/pickle.py:71: UserWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas will still use PyGEOS by default for now. To force to use and test Shapely 2.0, you have to set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:

import os
os.environ['USE_PYGEOS'] = '0'
import geopandas

In a future release, GeoPandas will switch to using Shapely by default. If you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).
  return pickle.loads(x, buffers=buffers)
/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/dask/dataframe/io/csv.py:194: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.
  df = reader(bio, **kwargs)
/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/dask/dataframe/io/csv.py:194: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.
  df = reader(bio, **kwargs)
/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/dask/dataframe/io/csv.py:194: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.
  df = reader(bio, **kwargs)
/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/dask/dataframe/io/csv.py:194: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.
  df = reader(bio, **kwargs)
slurmstepd: error: *** JOB 8875705 ON node2202 CANCELLED AT 2023-02-25T11:33:12 DUE TO TIME LIMIT ***
