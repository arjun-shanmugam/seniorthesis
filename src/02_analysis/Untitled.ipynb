{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0deda66a-ceb8-459b-9cb1-1b51d4d6d44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/geopandas/_compat.py:123: UserWarning: The Shapely GEOS version (3.11.1-CAPI-1.17.1) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_261584/2327955904.py:7: UserWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas will still use PyGEOS by default for now. To force to use and test Shapely 2.0, you have to set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:\n",
      "\n",
      "import os\n",
      "os.environ['USE_PYGEOS'] = '0'\n",
      "import geopandas\n",
      "\n",
      "In a future release, GeoPandas will switch to using Shapely by default. If you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).\n",
      "  import geopandas as gpd\n",
      "Computing ATTgt [workers=50]  100%|████████████████████| 1176/1176 [00:27<00:00, 43.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5.176985046535448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing ATTgt [workers=50]   68%|█████████████▌      | 797/1176 [00:21<00:10, 37.60it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 264\u001b[0m\n\u001b[1;32m    261\u001b[0m att_gt_below_median \u001b[38;5;241m=\u001b[39m ATTgt(data\u001b[38;5;241m=\u001b[39mbelow_median_subsample, cohort_name\u001b[38;5;241m=\u001b[39mtreatment_date_variable,\n\u001b[1;32m    262\u001b[0m                             base_period\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muniversal\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    263\u001b[0m formula \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00manalysis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ~ \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(pre_treatment_covariates)\n\u001b[0;32m--> 264\u001b[0m \u001b[43matt_gt_below_median\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformula\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformula\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrol_group\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnever_treated\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m average_post_treatment_att_below_median \u001b[38;5;241m=\u001b[39m att_gt_below_median\u001b[38;5;241m.\u001b[39maggregate(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevent\u001b[39m\u001b[38;5;124m'\u001b[39m, overall\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    266\u001b[0m point_estimate_below_median \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(average_post_treatment_att_below_median[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEventAggregationOverall\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    267\u001b[0m                                     \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/differences/attgt/attgt.py:688\u001b[0m, in \u001b[0;36mATTgt.fit\u001b[0;34m(self, formula, weights_name, control_group, base_delta, est_method, as_repeated_cross_section, boot_iterations, random_state, alpha, cluster_var, split_sample_by, n_jobs, backend, progress_bar)\u001b[0m\n\u001b[1;32m    676\u001b[0m     cluster_groups \u001b[38;5;241m=\u001b[39m get_cluster_groups(\n\u001b[1;32m    677\u001b[0m         data\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    678\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_matrix[cluster_var]\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    684\u001b[0m         cluster_var\u001b[38;5;241m=\u001b[39mcluster_var,\n\u001b[1;32m    685\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[38;5;66;03m# att\u001b[39;00m\n\u001b[0;32m--> 688\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mget_att_gt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_matrix\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfull_sample\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    692\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_matrix\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_result_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msample_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcohort_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcohort_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrata_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrata_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_weights_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontrol_group\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_control_group\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m    \u001b[49m\u001b[43manticipation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manticipation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_covariates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_x_covariates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_base\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_x_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_delta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_x_delta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_panel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_panel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_balanced_panel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_balanced_panel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcluster_by_entity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cluster_by_entity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43matt_function_ct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43matt_function_ct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackend_ct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs_ct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfull_sample\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# just for progress_bar\u001b[39;49;00m\n\u001b[1;32m    712\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrelease_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mboot_iterations\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43ms_idx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_sample_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[38;5;66;03m# standard errors & ci/cbands\u001b[39;00m\n\u001b[1;32m    718\u001b[0m res \u001b[38;5;241m=\u001b[39m get_standard_errors(\n\u001b[1;32m    719\u001b[0m     ntl\u001b[38;5;241m=\u001b[39mres,\n\u001b[1;32m    720\u001b[0m     cluster_groups\u001b[38;5;241m=\u001b[39mcluster_groups,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    728\u001b[0m     release_workers\u001b[38;5;241m=\u001b[39ms_idx \u001b[38;5;241m==\u001b[39m n_sample_names,\n\u001b[1;32m    729\u001b[0m )\n",
      "File \u001b[0;32m/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/differences/attgt/attgt_cal.py:393\u001b[0m, in \u001b[0;36mget_att_gt\u001b[0;34m(group_time, data, y_name, cohort_name, is_panel, is_balanced_panel, cluster_by_entity, x_covariates, x_base, x_delta, strata_name, weights_name, control_group, anticipation, att_function_ct, n_jobs_ct, backend_ct, progress_bar, sample_name, release_workers)\u001b[0m\n\u001b[1;32m    381\u001b[0m sample_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_name \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm_joblib(\n\u001b[1;32m    384\u001b[0m     tqdm(\n\u001b[1;32m    385\u001b[0m         disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m progress_bar,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    391\u001b[0m \n\u001b[1;32m    392\u001b[0m     \u001b[38;5;66;03m# compute the ct att. order of parameters must conform to did_single_gt()\u001b[39;00m\n\u001b[0;32m--> 393\u001b[0m     res_ntl \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs_ct\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend_ct\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdid_single_gt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m            \u001b[49m\u001b[43mentities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m            \u001b[49m\u001b[43mentity_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_total\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m            \u001b[49m\u001b[43my_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcohort_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstrata_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m            \u001b[49m\u001b[43mweights_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m            \u001b[49m\u001b[43mx_covariates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m            \u001b[49m\u001b[43mx_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m            \u001b[49m\u001b[43mx_delta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m            \u001b[49m\u001b[43manticipation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontrol_group\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m            \u001b[49m\u001b[43mis_panel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m            \u001b[49m\u001b[43mis_balanced_panel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcluster_by_entity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m            \u001b[49m\u001b[43matt_function_ct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgroup_time\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m release_workers:\n\u001b[1;32m    418\u001b[0m     get_reusable_executor()\u001b[38;5;241m.\u001b[39mshutdown(wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m/gpfs/home/ashanmu1/seniorthesis/venv/lib/python3.10/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/concurrent/futures/_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import contextily as cx\n",
    "import figure_utilities\n",
    "import constants\n",
    "from stats_utilities import produce_summary_statistics, select_controls, test_balance\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from panel_utilities import get_value_variable_names, prepare_df_for_DiD\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "import os\n",
    "from differences import ATTgt\n",
    "import pandas as pd\n",
    "\n",
    "# Store paths.\n",
    "INPUT_DATA_PANEL = \"../../data/03_cleaned/property_crime_panel_monthly.parquet\"\n",
    "INPUT_DATA_TRACTS = \"../../data/02_intermediate/tracts.csv\"\n",
    "INPUT_DATA_BOSTON_TRACTS_SHAPEFILE = \"../../data/01_raw/Census_2010_Tracts\"\n",
    "\n",
    "OUTPUT_TABLES = \"../../output/final_paper/tables\"\n",
    "OUTPUT_FIGURES = \"../../output/final_paper/figures\"\n",
    "\n",
    "# Read unrestricted dataset into memory.\n",
    "df = pd.read_parquet(INPUT_DATA_PANEL)\n",
    "\n",
    "# So we can use 'case_number' like a column\n",
    "df = df.reset_index()\n",
    "\n",
    "# Plot evictions spatially.\n",
    "unrestricted_gdf = gpd.GeoDataFrame(df,\n",
    "                                    geometry=gpd.points_from_xy(df['Longitude'],\n",
    "                                                                df['Latitude']))\n",
    "unrestricted_gdf = unrestricted_gdf.set_crs(\"EPSG:4326\")\n",
    "unrestricted_gdf = unrestricted_gdf.to_crs(\"EPSG:3857\")\n",
    "fig, ax = plt.subplots(figsize=(8, 10))\n",
    "ax.set_yticklabels([])\n",
    "ax.set_yticks([])\n",
    "ax.set_xticklabels([])\n",
    "ax.set_xticks([])\n",
    "unrestricted_gdf.plot(ax=ax,\n",
    "                      color='black',\n",
    "                      markersize=0.05)\n",
    "cx.add_basemap(ax=ax, crs=\"EPSG:3857\", source=cx.providers.Stamen.TonerLite)\n",
    "\n",
    "# Color census tracts by poverty rate.\n",
    "boston_tracts_gdf = gpd.read_file(INPUT_DATA_BOSTON_TRACTS_SHAPEFILE)[['GEOID10', 'geometry']].set_index('GEOID10')\n",
    "boston_tracts_gdf.index = boston_tracts_gdf.index.astype(int)\n",
    "tract_poverty_rates_df = pd.read_csv(INPUT_DATA_TRACTS, usecols=['tract_geoid', 'poor_share2010'],\n",
    "                                     index_col='tract_geoid')\n",
    "\n",
    "boston_tracts_gdf = pd.concat([boston_tracts_gdf, tract_poverty_rates_df], axis=1).dropna(\n",
    "    subset=['geometry', 'poor_share2010'])\n",
    "boston_tracts_gdf.plot(ax=ax, column=boston_tracts_gdf['poor_share2010'], cmap='OrRd', alpha=0.4, legend=True,\n",
    "                       legend_kwds={'label': \"Poverty Rate of Census Tract\",\n",
    "                                    'orientation': \"horizontal\",\n",
    "                                    'shrink': 0.25})\n",
    "\n",
    "figure_utilities.save_figure_and_close(fig, os.path.join(OUTPUT_FIGURES, \"evictions_map.png\"))\n",
    "\n",
    "# Plot the number of eviction filings over time.\n",
    "df.loc[:, 'last_day_of_file_month'] = (pd.to_datetime(df['file_date']) +\n",
    "                                       pd.tseries.offsets.MonthEnd(0))\n",
    "filings_per_month = df.groupby('last_day_of_file_month')['case_number'].count()\n",
    "\n",
    "# Plot eviction filing counts.\n",
    "fig, ax = plt.subplots()\n",
    "filings_per_month.plot(ax=ax, kind='line', color='black',\n",
    "                       zorder=100)\n",
    "ax.set_ylabel(\"Number of Evictions\")\n",
    "ax.set_xlabel(\"Month\")\n",
    "ax.grid(True)\n",
    "figure_utilities.save_figure_and_close(fig, os.path.join(OUTPUT_FIGURES, \"filings_over_time.png\"))\n",
    "\n",
    "\n",
    "# Produce summary statistics table.\n",
    "treatment_date_variable = 'latest_docket_date'\n",
    "outcomes_of_interest = ['group_0_crimes_500m']\n",
    "summary_statistics_unrestricted, variable_display_names_dict = produce_summary_statistics(df,\n",
    "                                                                                          treatment_date_variable=treatment_date_variable)\n",
    "\n",
    "# Rename columns.\n",
    "summary_statistics_unrestricted.index = summary_statistics_unrestricted.index.set_names([\"Panel\", \"Variable\"])\n",
    "column_display_names_dict = {'mean': \"Mean\", 'std': \"S.D.\", 'count': \"N\", '50%': 'Median'}\n",
    "\n",
    "summary_statistics_unrestricted = summary_statistics_unrestricted.sort_values(['Panel', 'Variable'])\n",
    "# Keep only outcomes of interest\n",
    "outcomes = constants.Variables.outcomes.copy()\n",
    "for outcome in outcomes:\n",
    "    if outcome not in outcomes_of_interest:\n",
    "        if f\"pre_treatment_change_in_{outcome}\" in summary_statistics_unrestricted.index.get_level_values(1):\n",
    "            summary_statistics_unrestricted = summary_statistics_unrestricted.drop(f\"pre_treatment_change_in_{outcome}\",\n",
    "                                                                                   level=1, axis=0)\n",
    "        if f\"total_twenty_seventeen_{outcome}\" in summary_statistics_unrestricted.index.get_level_values(1):\n",
    "            summary_statistics_unrestricted = summary_statistics_unrestricted.drop(f\"total_twenty_seventeen_{outcome}\",\n",
    "                                                                                   level=1, axis=0)\n",
    "\n",
    "# Drop Panel F.\n",
    "summary_statistics_unrestricted = summary_statistics_unrestricted.drop(\"Panel F: Post-treatment Outcomes\", level=0,\n",
    "                                                                       axis=0)\n",
    "\n",
    "# Drop median column.\n",
    "summary_statistics_unrestricted = summary_statistics_unrestricted.drop(columns='50%')\n",
    "\n",
    "# Export to LaTeX.\n",
    "filename = os.path.join(OUTPUT_TABLES, \"summary_statistics.tex\")\n",
    "latex = (summary_statistics_unrestricted\n",
    "         .rename(index=variable_display_names_dict)\n",
    "         .rename(columns=column_display_names_dict)\n",
    "         .style\n",
    "         .format(formatter={\n",
    "    'Mean': \"{:,.2f}\",\n",
    "    'Median': \"{:,.2f}\",\n",
    "    'S.D.': \"{:,.2f}\",\n",
    "    'N': \"{:,.0f}\"})\n",
    "         .format_index(\"\\\\textit{{{}}}\", escape=\"latex\", axis=0, level=0)\n",
    "         .to_latex(None,\n",
    "                   column_format=\"llcccc\",\n",
    "                   hrules=True,\n",
    "                   clines=\"skip-last;data\")).replace(\"{*}\", \"{4cm}\")\n",
    "with open(filename, 'w') as file:\n",
    "    file.write(latex)\n",
    "summary_statistics_unrestricted\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Produce treatment timings table.\n",
    "treatment_timings = (df\n",
    "                     .groupby(['latest_docket_month', 'judgment_for_plaintiff'])['case_number']\n",
    "                     .count()\n",
    "                     .reset_index()\n",
    "                     .fillna(0))\n",
    "treatment_timings = treatment_timings.pivot(index='latest_docket_month', columns='judgment_for_plaintiff').fillna(0)\n",
    "treatment_timings.columns = [\"Cases Won By Defendant\", \"Cases Won By Plaintiff\"]\n",
    "portion_of_all_cases = (treatment_timings['Cases Won By Plaintiff'] + treatment_timings[\n",
    "    'Cases Won By Defendant']) / len(df)\n",
    "treatment_timings = pd.concat([treatment_timings, portion_of_all_cases.rename('Portion of All Cases')], axis=1)\n",
    "sum_across_filing_date = pd.DataFrame(treatment_timings.sum(axis=0)).T\n",
    "sum_across_filing_date.index = [\"All Months\"]\n",
    "treatment_timings = pd.concat([sum_across_filing_date, treatment_timings], axis=0)\n",
    "treatment_timings.index = treatment_timings.index.rename(\"Last Docket Date\")\n",
    "\n",
    "# Export to LaTeX.\n",
    "filename = os.path.join(OUTPUT_TABLES, \"treatment_timings.tex\")\n",
    "treatment_timings.style.format(formatter={'Cases Won By Plaintiff': '{:,.0f}',\n",
    "                                          'Cases Won By Defendant': '{:,.0f}',\n",
    "                                          'Portion of All Cases': '{:0.2f}'}).to_latex(filename, column_format=\"lccc\",\n",
    "                                                                                       hrules=True)\n",
    "treatment_timings\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Calculate percent of cases which are in high poverty neighborhoods.\n",
    "df = df.loc[df['judgment_for_plaintiff'] == 1, :]\n",
    "original_N = len(df)\n",
    "cases_in_poor_tracts = len(df.loc[df['poor_share2010'] > 0.20, :])\n",
    "cases_in_poor_tracts / original_N\n",
    "\n",
    "# # Main Results\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Read fresh copy of unrestricted dataset into memory.\n",
    "df = pd.read_parquet(INPUT_DATA_PANEL)\n",
    "treatment_date_variable = 'latest_docket_month'  # Store treatment date variable.\n",
    "analysis = 'group_0_crimes_500m'\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Generate value variables list and dictionaries mapping between months and integers.\n",
    "weekly_value_vars_crime, month_to_int_dictionary, int_to_month_dictionary = get_value_variable_names(df, analysis)\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "covariates_exploration_df = select_controls(df=df, analysis=analysis,\n",
    "                                            treatment_date_variable=treatment_date_variable,\n",
    "                                            output_directory=OUTPUT_TABLES)\n",
    "covariates_exploration_df\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "balance_table, pre_treatment_covariates = test_balance(df, analysis, covariates_exploration_df, OUTPUT_TABLES)\n",
    "balance_table\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Prepare df for use with the differences package.\n",
    "df = df.reset_index()\n",
    "df = prepare_df_for_DiD(df=df,\n",
    "                        analysis=analysis,\n",
    "                        treatment_date_variable=treatment_date_variable,\n",
    "                        pre_treatment_covariates=pre_treatment_covariates,\n",
    "                        missing_indicators=[],\n",
    "                        value_vars=weekly_value_vars_crime,\n",
    "                        period_to_int_dictionary=month_to_int_dictionary)\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Run DiD conditional on covariates.\n",
    "att_gt_all_crimes = ATTgt(data=df, cohort_name=treatment_date_variable, base_period='universal')\n",
    "formula = f'{analysis} ~ ' + '+'.join(pre_treatment_covariates)\n",
    "result = att_gt_all_crimes.fit(formula=formula, control_group='never_treated', n_jobs=-1, progress_bar=True)\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "print(att_gt_all_crimes.aggregate('event', 'all')['EventAggregationOverall'].iloc[0, 2])\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Plot D.R. ATT(t-g)s on a long horizon.\n",
    "fig, ax = plt.subplots(layout='constrained')\n",
    "figure_utilities.aggregate_by_event_time_and_plot(att_gt_all_crimes, start_period=-5,\n",
    "                                                  end_period=36,\n",
    "                                                  title=\"\", ax=ax)\n",
    "\n",
    "figure_utilities.save_figure_and_close(fig, os.path.join(OUTPUT_FIGURES, \"att_gt_dr_all_crimes.png\"))\n",
    "\n",
    "# # Heterogenous Impacts\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "# Check for heterogeneous treatment effects.\n",
    "subsample_variables = ['poor_share2010', 'share_white2010', 'popdensity2010']\n",
    "# Read fresh copy of unrestricted dataset into memory.\n",
    "df = pd.read_parquet(INPUT_DATA_PANEL)\n",
    "treatment_date_variable = 'latest_docket_month'  # Store treatment date variable.\n",
    "analysis = 'group_0_crimes_500m'\n",
    "point_estimates = []\n",
    "ci_uppers = []\n",
    "ci_lowers = []\n",
    "\n",
    "for subsample_variable in subsample_variables:\n",
    "    # Get results on below median subsample.\n",
    "    below_median_subsample = df[df[subsample_variable] < df[subsample_variable].median()].copy()\n",
    "    weekly_value_vars_crime, month_to_int_dictionary, int_to_month_dictionary = get_value_variable_names(\n",
    "        below_median_subsample, analysis)\n",
    "    covariates_exploration_df = select_controls(df=below_median_subsample, analysis=analysis,\n",
    "                                                treatment_date_variable=treatment_date_variable)\n",
    "    balance_table, pre_treatment_covariates = test_balance(below_median_subsample, analysis, covariates_exploration_df)\n",
    "    below_median_subsample = below_median_subsample.reset_index()\n",
    "    below_median_subsample = prepare_df_for_DiD(df=below_median_subsample,\n",
    "                                                analysis=analysis,\n",
    "                                                treatment_date_variable=treatment_date_variable,\n",
    "                                                pre_treatment_covariates=pre_treatment_covariates,\n",
    "                                                missing_indicators=[],\n",
    "                                                value_vars=weekly_value_vars_crime,\n",
    "                                                period_to_int_dictionary=month_to_int_dictionary)\n",
    "    # Run DiD conditional on covariates.\n",
    "    att_gt_below_median = ATTgt(data=below_median_subsample, cohort_name=treatment_date_variable,\n",
    "                                base_period='universal')\n",
    "    formula = f'{analysis} ~ ' + '+'.join(pre_treatment_covariates)\n",
    "    att_gt_below_median.fit(formula=formula, control_group='never_treated', n_jobs=-1, progress_bar=True)\n",
    "    average_post_treatment_att_below_median = att_gt_below_median.aggregate('event', overall=True)\n",
    "    point_estimate_below_median = round(average_post_treatment_att_below_median['EventAggregationOverall'].iloc[0, 0],\n",
    "                                        2)\n",
    "    ci_upper_below_median = round(average_post_treatment_att_below_median['EventAggregationOverall'].iloc[0, 3], 2)\n",
    "    ci_lower_below_median = round(average_post_treatment_att_below_median['EventAggregationOverall'].iloc[0, 2], 2)\n",
    "    point_estimates.append(point_estimate_below_median)\n",
    "    ci_uppers.append(ci_upper_below_median)\n",
    "    ci_lowers.append(ci_lower_below_median)\n",
    "\n",
    "    # Get results on above median subsample.\n",
    "    above_median_subsample = df[df[subsample_variable] > df[subsample_variable].median()].copy()\n",
    "    weekly_value_vars_crime, month_to_int_dictionary, int_to_month_dictionary = get_value_variable_names(\n",
    "        above_median_subsample, analysis)\n",
    "    covariates_exploration_df = select_controls(df=above_median_subsample, analysis=analysis,\n",
    "                                                treatment_date_variable=treatment_date_variable)\n",
    "    balance_table, pre_treatment_covariates = test_balance(above_median_subsample, analysis, covariates_exploration_df)\n",
    "    above_median_subsample = above_median_subsample.reset_index()\n",
    "    above_median_subsample = prepare_df_for_DiD(df=above_median_subsample,\n",
    "                                                analysis=analysis,\n",
    "                                                treatment_date_variable=treatment_date_variable,\n",
    "                                                pre_treatment_covariates=pre_treatment_covariates,\n",
    "                                                missing_indicators=[],\n",
    "                                                value_vars=weekly_value_vars_crime,\n",
    "                                                period_to_int_dictionary=month_to_int_dictionary)\n",
    "    # Run DiD conditional on covariates.\n",
    "    att_gt_above_median = ATTgt(data=above_median_subsample, cohort_name=treatment_date_variable,\n",
    "                                base_period='universal')\n",
    "    formula = f'{analysis} ~ ' + '+'.join(pre_treatment_covariates)\n",
    "    att_gt_above_median.fit(formula=formula, control_group='never_treated', n_jobs=-1, progress_bar=True)\n",
    "    average_post_treatment_att_above_median = att_gt_above_median.aggregate('event', overall=True)\n",
    "    point_estimate_above_median = round(average_post_treatment_att_above_median['EventAggregationOverall'].iloc[0, 0],\n",
    "                                        2)\n",
    "    ci_upper_above_median = round(average_post_treatment_att_above_median['EventAggregationOverall'].iloc[0, 3], 2)\n",
    "    ci_lower_above_median = round(average_post_treatment_att_above_median['EventAggregationOverall'].iloc[0, 2], 2)\n",
    "    point_estimates.append(point_estimate_above_median)\n",
    "    ci_uppers.append(ci_upper_above_median)\n",
    "    ci_lowers.append(ci_lower_above_median)\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "figure_utilities.plot_labeled_vline(ax, x=0, text=\"\", color='black', linestyle='-')\n",
    "\n",
    "for i, (ci_lower, ci_upper) in enumerate(zip(ci_lowers, ci_uppers)):\n",
    "    ax.hlines(y=i, xmin=ci_lower, xmax=ci_upper, color='black')\n",
    "ax.scatter(point_estimates, range(len(point_estimates)), color='black', s=7)\n",
    "ax.set_yticks(ticks=range(len(point_estimates)),\n",
    "              labels=[\"Below median poverty rate, 2010\", \"Above median poverty rate, 2010\",\n",
    "                      \"Below median share white, 2010\", \"Above median share white, 2010\",\n",
    "                      \"Below median population density, 2010\", \"Above median population density, 2010\"])\n",
    "ax.set_ylabel(\"Sample Restriction\")\n",
    "ax.set_xlabel(\"Average Post-Treatment ATT\")\n",
    "\n",
    "figure_utilities.save_figure_and_close(fig, os.path.join(OUTPUT_FIGURES, \"heterogenous_effects.png\"))\n",
    "\n",
    "# # Mechanisms\n",
    "\n",
    "# ## Placebo Test\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Read fresh copy of unrestricted dataset into memory.\n",
    "df = pd.read_parquet(INPUT_DATA_PANEL)\n",
    "treatment_date_variable = 'latest_docket_month'  # Store treatment date variable.\n",
    "analysis = 'group_1_crimes_500m'\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Generate value variables list and dictionaries mapping between months and integers.\n",
    "weekly_value_vars_crime, month_to_int_dictionary, int_to_month_dictionary = get_value_variable_names(df, analysis)\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "covariates_exploration_df = select_controls(df=df, analysis=analysis,\n",
    "                                            treatment_date_variable=treatment_date_variable)\n",
    "covariates_exploration_df\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "balance_table, pre_treatment_covariates = test_balance(df, analysis, covariates_exploration_df)\n",
    "balance_table\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Prepare df for use with the differences package.\n",
    "df = df.reset_index()\n",
    "df = prepare_df_for_DiD(df=df,\n",
    "                        analysis=analysis,\n",
    "                        treatment_date_variable=treatment_date_variable,\n",
    "                        pre_treatment_covariates=pre_treatment_covariates,\n",
    "                        missing_indicators=[],\n",
    "                        value_vars=weekly_value_vars_crime,\n",
    "                        period_to_int_dictionary=month_to_int_dictionary)\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Run DiD conditional on covariates.\n",
    "att_gt_placebo_crimes = ATTgt(data=df, cohort_name=treatment_date_variable, base_period='universal')\n",
    "formula = f'{analysis} ~ ' + '+'.join(pre_treatment_covariates)\n",
    "result = att_gt_placebo_crimes.fit(formula=formula, control_group='never_treated', n_jobs=-1, progress_bar=True)\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Plot D.R. ATT(t-g)s for placebo crimes next to D.R. ATT(t-g)s for all crimes.\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, layout='constrained', sharey=True)\n",
    "\n",
    "figure_utilities.aggregate_by_event_time_and_plot(att_gt_all_crimes, start_period=-5,\n",
    "                                                  end_period=36,\n",
    "                                                  title=\"All Crime Incidents as Outcome\", ax=ax1)\n",
    "figure_utilities.aggregate_by_event_time_and_plot(att_gt_placebo_crimes, start_period=-5,\n",
    "                                                  end_period=36,\n",
    "                                                  title=\"Subset of Crime Incidents as Outcome\", ax=ax2)\n",
    "\n",
    "figure_utilities.save_figure_and_close(fig, os.path.join(OUTPUT_FIGURES, \"att_gt_dr_placebo_crimes.png\"))\n",
    "\n",
    "# ## Estimation on Cases Concluding During Warm vs. Cold Months\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Read fresh copy of unrestricted dataset into memory; limit to warm months\n",
    "df = pd.read_parquet(INPUT_DATA_PANEL)\n",
    "warm_months = ['2019-05', '2019-06', '2019-07', '2019-08', '2019-09', '2019-10']\n",
    "df = df.loc[df['latest_docket_month'].isin(warm_months), :]\n",
    "treatment_date_variable = 'latest_docket_month'  # Store treatment date variable.\n",
    "analysis = 'group_0_crimes_500m'\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Generate value variables list and dictionaries mapping between months and integers.\n",
    "weekly_value_vars_crime, month_to_int_dictionary, int_to_month_dictionary = get_value_variable_names(df, analysis)\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "covariates_exploration_df = select_controls(df=df, analysis=analysis,\n",
    "                                            treatment_date_variable=treatment_date_variable)\n",
    "covariates_exploration_df\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "balance_table, pre_treatment_covariates = test_balance(df, analysis, covariates_exploration_df)\n",
    "balance_table\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Prepare df for use with the differences package.\n",
    "df = df.reset_index()\n",
    "df = prepare_df_for_DiD(df=df,\n",
    "                        analysis=analysis,\n",
    "                        treatment_date_variable=treatment_date_variable,\n",
    "                        pre_treatment_covariates=pre_treatment_covariates,\n",
    "                        missing_indicators=[],\n",
    "                        value_vars=weekly_value_vars_crime,\n",
    "                        period_to_int_dictionary=month_to_int_dictionary)\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Run DiD conditional on covariates.\n",
    "att_gt_warm = ATTgt(data=df, cohort_name=treatment_date_variable, base_period='universal')\n",
    "formula = f'{analysis} ~ ' + '+'.join(pre_treatment_covariates)\n",
    "result = att_gt_warm.fit(formula=formula, control_group='never_treated', n_jobs=-1, progress_bar=True)\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Read fresh copy of unrestricted dataset into memory; limit to warm months\n",
    "df = pd.read_parquet(INPUT_DATA_PANEL)\n",
    "cold_months = ['2019-04', '2019-11', '2019-12', '2020-01', '2020-02', '2020-03']\n",
    "df = df.loc[df['latest_docket_month'].isin(cold_months), :]\n",
    "treatment_date_variable = 'latest_docket_month'  # Store treatment date variable.\n",
    "analysis = 'group_0_crimes_500m'\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Generate value variables list and dictionaries mapping between months and integers.\n",
    "weekly_value_vars_crime, month_to_int_dictionary, int_to_month_dictionary = get_value_variable_names(df, analysis)\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "covariates_exploration_df = select_controls(df=df, analysis=analysis,\n",
    "                                            treatment_date_variable=treatment_date_variable)\n",
    "covariates_exploration_df\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "balance_table, pre_treatment_covariates = test_balance(df, analysis, covariates_exploration_df)\n",
    "balance_table\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Prepare df for use with the differences package.\n",
    "df = df.reset_index()\n",
    "df = prepare_df_for_DiD(df=df,\n",
    "                        analysis=analysis,\n",
    "                        treatment_date_variable=treatment_date_variable,\n",
    "                        pre_treatment_covariates=pre_treatment_covariates,\n",
    "                        missing_indicators=[],\n",
    "                        value_vars=weekly_value_vars_crime,\n",
    "                        period_to_int_dictionary=month_to_int_dictionary)\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Run DiD conditional on covariates.\n",
    "att_gt_cold = ATTgt(data=df, cohort_name=treatment_date_variable, base_period='universal')\n",
    "formula = f'{analysis} ~ ' + '+'.join(pre_treatment_covariates)\n",
    "result = att_gt_cold.fit(formula=formula, control_group='never_treated', n_jobs=-1, progress_bar=True)\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Plot D.R. ATT(t-g)s for placebo crimes next to D.R. ATT(t-g)s for all crimes.\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, layout='constrained', sharey=True)\n",
    "\n",
    "figure_utilities.aggregate_by_event_time_and_plot(att_gt_warm, start_period=-5,\n",
    "                                                  end_period=36,\n",
    "                                                  title=\"Cases Concluding in\\nMay 2019-October 2019\", ax=ax1)\n",
    "figure_utilities.aggregate_by_event_time_and_plot(att_gt_cold, start_period=-5,\n",
    "                                                  end_period=36,\n",
    "                                                  title=\"Cases Concluding in\\nNovember 2019-April 2020\", ax=ax2)\n",
    "\n",
    "figure_utilities.save_figure_and_close(fig, os.path.join(OUTPUT_FIGURES, \"att_gt_dr_temperature.png\"))\n",
    "\n",
    "# # Robustness\n",
    "\n",
    "# Read fresh copy of unrestricted dataset into memory.\n",
    "df = pd.read_parquet(INPUT_DATA_PANEL)\n",
    "treatment_date_variable = 'latest_docket_month'  # Store treatment date variable.\n",
    "analysis = 'group_0_crimes_125m'\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Generate value variables list and dictionaries mapping between months and integers.\n",
    "weekly_value_vars_crime, month_to_int_dictionary, int_to_month_dictionary = get_value_variable_names(df, analysis)\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "covariates_exploration_df = select_controls(df=df, analysis=analysis,\n",
    "                                            treatment_date_variable=treatment_date_variable,\n",
    "                                            output_directory=OUTPUT_TABLES)\n",
    "covariates_exploration_df\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "balance_table, pre_treatment_covariates = test_balance(df, analysis, covariates_exploration_df, OUTPUT_TABLES)\n",
    "balance_table\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Prepare df for use with the differences package.\n",
    "df = df.reset_index()\n",
    "df = prepare_df_for_DiD(df=df,\n",
    "                        analysis=analysis,\n",
    "                        treatment_date_variable=treatment_date_variable,\n",
    "                        pre_treatment_covariates=pre_treatment_covariates,\n",
    "                        missing_indicators=[],\n",
    "                        value_vars=weekly_value_vars_crime,\n",
    "                        period_to_int_dictionary=month_to_int_dictionary)\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Run DiD conditional on covariates.\n",
    "att_gt_non_payment = ATTgt(data=df, cohort_name=treatment_date_variable, base_period='universal')\n",
    "formula = f'{analysis} ~ ' + '+'.join(pre_treatment_covariates)\n",
    "result = att_gt_non_payment.fit(formula=formula, control_group='never_treated', n_jobs=-1, progress_bar=True)\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Plot D.R. ATT(t-g)s on a long horizon.\n",
    "fig, ax = plt.subplots(layout='constrained')\n",
    "figure_utilities.aggregate_by_event_time_and_plot(att_gt_non_payment, start_period=-5,\n",
    "                                                  end_period=36,\n",
    "                                                  title=\"\", ax=ax)\n",
    "\n",
    "figure_utilities.save_figure_and_close(fig, os.path.join(OUTPUT_FIGURES, \"att_gt_dr_100m.png\"))\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Read fresh copy of unrestricted dataset into memory.\n",
    "df = pd.read_parquet(INPUT_DATA_PANEL)\n",
    "treatment_date_variable = 'latest_docket_month'  # Store treatment date variable.\n",
    "analysis = 'group_0_crimes_250m'\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Generate value variables list and dictionaries mapping between months and integers.\n",
    "weekly_value_vars_crime, month_to_int_dictionary, int_to_month_dictionary = get_value_variable_names(df, analysis)\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "covariates_exploration_df = select_controls(df=df, analysis=analysis,\n",
    "                                            treatment_date_variable=treatment_date_variable,\n",
    "                                            output_directory=OUTPUT_TABLES)\n",
    "covariates_exploration_df\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "balance_table, pre_treatment_covariates = test_balance(df, analysis, covariates_exploration_df, OUTPUT_TABLES)\n",
    "balance_table\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Prepare df for use with the differences package.\n",
    "df = df.reset_index()\n",
    "df = prepare_df_for_DiD(df=df,\n",
    "                        analysis=analysis,\n",
    "                        treatment_date_variable=treatment_date_variable,\n",
    "                        pre_treatment_covariates=pre_treatment_covariates,\n",
    "                        missing_indicators=[],\n",
    "                        value_vars=weekly_value_vars_crime,\n",
    "                        period_to_int_dictionary=month_to_int_dictionary)\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Run DiD conditional on covariates.\n",
    "att_gt_non_payment = ATTgt(data=df, cohort_name=treatment_date_variable, base_period='universal')\n",
    "formula = f'{analysis} ~ ' + '+'.join(pre_treatment_covariates)\n",
    "result = att_gt_non_payment.fit(formula=formula, control_group='never_treated', n_jobs=-1, progress_bar=True)\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Plot D.R. ATT(t-g)s on a long horizon.\n",
    "fig, ax = plt.subplots(layout='constrained')\n",
    "figure_utilities.aggregate_by_event_time_and_plot(att_gt_non_payment, start_period=-5,\n",
    "                                                  end_period=36,\n",
    "                                                  title=\"\", ax=ax)\n",
    "\n",
    "figure_utilities.save_figure_and_close(fig, os.path.join(OUTPUT_FIGURES, \"att_gt_dr_250m.png\"))\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# %%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdc2222-3643-4023-b3c0-2b383fea83da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
